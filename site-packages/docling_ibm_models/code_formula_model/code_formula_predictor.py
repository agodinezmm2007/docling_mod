# code_formula_predictor.py
# "DRASTIC MEASURE" VERSION
# This merges the line-by-line flow of your "simple version" into the class structure.
from typing import Iterable, Optional, Union
import logging
from typing import List, Union
from pathlib import Path
import re
import numpy as np
import torch
from PIL import Image

from transformers import AutoProcessor, AutoModelForVision2Seq, StoppingCriteria, StoppingCriteriaList
from docling_core.types.doc.document import DocTagsDocument
from docling_core.types.doc import DoclingDocument
from docling_core.types.doc.labels import DocItemLabel
# from latexcleaner import LatexToMarkdown, normalize_bounding_boxes  # if needed

_log = logging.getLogger(__name__)



import re

class RegexRepetitionStoppingCriteria(StoppingCriteria):
    def __init__(self, tokenizer, repetition_threshold=3, min_repeat_pattern=4):
        self.tokenizer = tokenizer
        self.repetition_threshold = repetition_threshold
        self.min_repeat_pattern = min_repeat_pattern

    def __call__(self, input_ids, scores, **kwargs):
        decoded_output = self.tokenizer.decode(input_ids[0], skip_special_tokens=True)

        # Regex pattern: detects any repeated short sequence (4+ chars), 3 or more times consecutively at end.
        pattern = r"(.{%d,}?)\1{%d,}$" % (self.min_repeat_pattern, self.repetition_threshold - 1)
        match = re.search(pattern, decoded_output)

        if match:
            repeating_sequence = match.group(1)
            logging.warning(f"Repetitive generation detected with pattern: '{repeating_sequence}'")
            return True

        return False

class CodeFormulaPredictor:
    """
    Modified to use ds4sd/SmolDocling-256M-preview (Idefics3).
    
    - If label=="code", produce doc-ling style <code> blocks 
    - If label=="formula", produce doc-ling style <formula> blocks
    - Then parse them to extract code or LaTeX.
    """

    def __init__(
        self,
        artifacts_path: str,
        device: str = "cpu",
        num_threads: int = 4,
    ):
        self._device = device
        self._num_threads = num_threads
        if self._device == "cpu":
            torch.set_num_threads(self._num_threads)

        _log.info(f"Loading SmolDocling from {artifacts_path} on {device}...")

        # Specify the attention implementation dynamically
        if torch.cuda.is_available():
            self._device = "cuda"
            attn_impl = "flash_attention_2"
            dtype = torch.bfloat16
        else:
            self._device = "cpu"
            attn_impl = "eager"
            dtype = torch.float32

        # New logging style to match your simpler test:
        _log.info(
            "Initializing Processor and Model with model: %s, torch_dtype: %s, _attn_implementation: %s, on device: %s",
            artifacts_path, dtype, attn_impl, self._device
        )

        self._processor = AutoProcessor.from_pretrained(artifacts_path)

        self._model = AutoModelForVision2Seq.from_pretrained(
            artifacts_path,
            torch_dtype=dtype,
            device_map="cpu",
            _attn_implementation=attn_impl,
        )
        # Explicitly move to GPU after initialization
        self._model.to(device)
        self._model.eval()
        _log.info("SmolDoclingPredictor init complete. Device=%s", self._device)


        self.stopping_criteria = StoppingCriteriaList([
            RegexRepetitionStoppingCriteria(
                tokenizer=self._processor.tokenizer,
                repetition_threshold=4,
                min_repeat_pattern=4
            )
        ])

    def info(self) -> dict:
        return {
            "device": self._device,
            "num_threads": self._num_threads,
        }

    def _get_prompt(self, label: str) -> str:
        """
        Construct a minimal doc-ling style prompt for code vs. formula bounding-box snippet.
        Customize if needed. 
        We'll request doc-ling style output, e.g. <formula> or <code> blocks.
        """
        _log.debug("Generating chat message for label: %s", label)
        if label == "code":
            prompt_text = "Convert code to text."
        elif label == "formula":
            prompt_text = "Convert formula to LaTeX."
        else:
            prompt_text = "Convert this page to docling."

        return prompt_text


    def _export_snippet_doctags_html(
            self, 
            doctag_output: str, 
            img: Image.Image, 
            snippet_id: str, 
            output_dir="/mnt/c/Users/WSTATION/Desktop/NEW_ETL/snippet_html"
            ):
        """
        Debugging helper to export snippet-level DocTags and associated image as HTML.

        Initializes DoclingDocument with a default name ("Document") first,
        then renames it dynamically to snippet-specific name.

        Functionally, everything continues to work exactly as before. Loading, enrichment,
        parsing, extraction, etc. all remain unaffected. When calling save_as_html(),
        the new snippet-specific name appears in the exported HTML.
        """
        
        from pathlib import Path
        try:
            output_path = Path(output_dir)
            doc_folder_name = snippet_id.rsplit("_item_", 1)[0]
            doc_folder = output_path / doc_folder_name
            doc_folder.mkdir(parents=True, exist_ok=True)



            # Build full base name inside that doc_folder
            base_name = doc_folder / f"snippet_{snippet_id}_raw_doctags"

            # Build HTML filename, and handle collisions
            # html_filename = output_path / f"{base_name}.html"
            html_filename = Path(str(base_name) + ".html")
            counter = 1
            while html_filename.exists():
                counter += 1
                # html_filename = output_path / f"{base_name}_{counter}.html"
                html_filename = Path(f"{base_name}_{counter}.html")

            # Save snippet image as PNG for correlation with HTML
            image_filename = html_filename.with_suffix(".png")

            # Construct DocTagsDocument directly from snippet data
            doctags_doc = DocTagsDocument.from_doctags_and_image_pairs([doctag_output], [img])

            # Initialize with fixed name first, then rename dynamically
            doc = DoclingDocument(name=f"Snippet_{snippet_id}")
            doc.load_from_doctags(doctags_doc)

            # Write files
            img.save(image_filename, format="PNG")
            doc.save_as_html(html_filename)

            _log.info(f"[Snippet ID {snippet_id}] DocTags exported to HTML at: {html_filename}")
            _log.info(f"[Snippet ID {snippet_id}] Snippet image saved at: {image_filename}")

        except Exception as e:
            _log.error(f"[Snippet ID {snippet_id}] Failed to export DocTags HTML: {e}", exc_info=True)

    @torch.inference_mode()
    def predict(
        self,
        images: List[Union[Image.Image, np.ndarray]],
        labels: List[str],
        snippet_ids: Optional[List[str]] = None  # <--- NEW param
    ) -> List[str]:
        """
        Replicates "simple script" flow for each snippet (image+label).
        No generation_config, no advanced stopping criteria. Just a single call
        to model.generate(..., max_new_tokens=700) with the "Convert this formula to LaTeX." style prompt.

        Then we parse the doc-ling output afterwards.
        """
        if snippet_ids is not None and len(snippet_ids) != len(images):
            raise ValueError("snippet_ids length must match images length")

        if len(images) != len(labels):
            raise ValueError("images and labels must have same length")

        _log.info("Starting prediction for %d images with labels: %s", len(images), labels)
        results = []


        # 2) For each snippet, build prompt, create input, call model.generate
        # for i, (img, lbl) in enumerate(zip(images, labels)):
        #     if not isinstance(img, Image.Image):
        #         raise TypeError(f"Snippet {i} is not a PIL Image => got {type(img)}")
            
        # 2) For each snippet, build prompt, create input, call model.generate
        for i, (img, lbl) in enumerate(zip(images, labels)):
            # 1) snippet_id logic
            if snippet_ids:
                snippet_id = snippet_ids[i]   # e.g. "pdf_row_42_item_0"
            else:
                snippet_id = f"snippet_{i}"   # fallback if none provided

            # 2.5) Check image type
            if not isinstance(img, Image.Image):
                raise TypeError(f"Snippet {i} is not a PIL Image => got {type(img)}")            
            
        
            snippet_prompt_text = self._get_prompt(lbl)
            # Build the conversation with a single user message
            conversation = [
                {"role": "user", "content": [{"type": "image"}, {"type": "text", "text": snippet_prompt_text}]}
            ]
            final_prompt = self._processor.apply_chat_template(conversation, add_generation_prompt=True)
            _log.debug("Snippet %s final prompt:\n%s", snippet_id, final_prompt) # "i" replaec with "snippet_id"

            # 3) Prepare inputs => same logic as simple script
            inputs = self._processor(
                text=final_prompt,
                images=[img],
                return_tensors="pt"
            ).to(self._device)

            prompt_len = inputs["input_ids"].shape[1]
            _log.debug(
                "Snippet %s => input_ids shape=%s, prompt_len=%d",
                snippet_id, inputs["input_ids"].shape, prompt_len # "i" replaec with "snippet_id"
            )
            

            # 4) (Optional) disable cache or clear CUDA:
            torch.cuda.empty_cache()
            self._model.config.use_cache = False

            # 5) Generate
            generated_ids = self._model.generate(
                **inputs, 
                max_new_tokens=400,
                stopping_criteria=self.stopping_criteria,
                # do_sample=False
                # temperature=0.0,
            )
            _log.debug("Snippet %s: generation shape=%s", snippet_id, generated_ids.shape) # "i" replaec with "snippet_id"

            # 6) Trim out the prompt tokens
            output_ids = generated_ids[:, prompt_len:]
            # 7) decode
            raw_text = self._processor.batch_decode(output_ids, skip_special_tokens=False)[0].lstrip()

            # 8) Optionally log token count
            token_count = len(self._processor.tokenizer.encode(raw_text))
            _log.debug("Snippet %s raw docling: (tokens=%d)\n%s", snippet_id, token_count, raw_text) # "i" replaec with "snippet_id"

            # Early detection of repetition-induced stopping
            if token_count == 0 or not raw_text.strip():
                _log.warning(f"Snippet {snippet_id} generated empty or repetitive text. Skipping.")
                results.append("")  # Skip malformed snippet
                continue

            # 9) Export snippet doc-ling HTML for debugging
            # snippet_id = f"snippet_{i}"
            # self._export_snippet_doctags_html(raw_text, img, snippet_id)

            # 10) parse doc-ling => recognized text
            recognized_str = self._parse_docling_output(raw_text, lbl, img)
            results.append(recognized_str)

        _log.info("All done. Returning %d recognized text results.", len(results))
        return results
        #---------------------------------------------
        # PREDICTING DOC TAGS
        # BELOW IS A NEW FUNCTION WHICH TRIES TO IMPLEMENT SMOLDOCLING COMPATIBLE LOGIC
        # WORK IN PROGRESS, MANY THINGS LEFT TO FIX AND INTEGRATE. SEE DOCSTRING FOR DETAILS
        #---------------------------------------------


    def _parse_docling_output(self, raw_text: str, label: str, snippet_img: Image.Image) -> str:
        """
        Mimics simple script final step: parse doc-ling <formula> or <code>.
        If no recognized text items, fallback to the raw text.
        """
        _log.debug("Starting _parse_docling_output")
        _log.debug("Raw SmolDocling output at parse_docling_output:\n%s", raw_text)
        # We'll parse doc tags via docling

        # Step 1: Create a DocTagsDocument from the raw text and image
        try:
            _log.debug("Creating DocTagsDocument from raw_text and snippet_img")
            doctags_doc = DocTagsDocument.from_doctags_and_image_pairs([raw_text], [snippet_img])
            _log.debug("DocTagsDocument created successfully: %s", doctags_doc)
        except Exception as e:
            _log.error("Error creating DocTagsDocument: %s", e, exc_info=True)
            return "" # No fallback to raw_text here
        
        # Step 2: Load the DocTagsDocument into a DoclingDocument
        try:
            doc = DoclingDocument(name="Document")
            _log.debug("Loading DocTagsDocument into DoclingDocument")
            doc.load_from_doctags(doctags_doc)
            _log.debug("DoclingDocument loaded successfully. Extracted texts: %s", doc.texts)
        except Exception as e:
            _log.error("Error loading DocTagsDocument into DoclingDocument: %s", e, exc_info=True)
            return "" # No fallback to raw_text here

        # Step 3: Extract recognized text items based on the label
        recognized_str = ""
        try:
            _log.debug("Extracting text items from DoclingDocument")
            for txt_item in doc.texts:
                _log.debug("Processing text item: label=%s, text=%s", txt_item.label, txt_item.text)
                if label == "code" and txt_item.label == DocItemLabel.CODE:
                    recognized_str += txt_item.text + "\n"
                elif label == "formula" and txt_item.label == DocItemLabel.FORMULA:
                    recognized_str += txt_item.text + "\n"
        except Exception as e:
            _log.error("Error extracting text items from DoclingDocument: %s", e, exc_info=True)
            return ""  # No fallback to raw_text here
        
        # Check validity explicitly
        recognized_str = recognized_str.strip()
        if not recognized_str or "<formula><loc_" in recognized_str:
            _log.warning("Extracted text is empty or malformed. Skipping formula.")
            return "MALFORMED_FORMULA"
        else:
            _log.debug("Recognized string extracted: %s", recognized_str)


        return recognized_str